{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c73f460a-4602-4d41-b1a1-d493f85d3e14",
   "metadata": {},
   "source": [
    "Step 1. DATA PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bb1f14b-59e5-4b51-beb9-775896124650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: implicit in c:\\users\\madhura\\appdata\\roaming\\python\\python311\\site-packages (0.7.2)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from implicit) (1.26.4)\n",
      "Requirement already satisfied: scipy>=0.16 in c:\\programdata\\anaconda3\\lib\\site-packages (from implicit) (1.11.4)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\programdata\\anaconda3\\lib\\site-packages (from implicit) (4.65.0)\n",
      "Requirement already satisfied: threadpoolctl in c:\\programdata\\anaconda3\\lib\\site-packages (from implicit) (2.2.0)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm>=4.27->implicit) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install implicit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e67eb7e4-d4f9-4e8a-85ef-d161d2b65748",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bd5de92-5b2e-45e6-9de7-4402ce67d91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert text transcriptions from individual text files of into a CSV format\n",
    "#transcription.csv file formation\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Directory containing the Categorical folder\n",
    "directory = 'E:/IIT-B/Dataset/Transcriptions'\n",
    "\n",
    "# Initialize lists to store utterance IDs, Time and Transcriptions\n",
    "utterance_ids = []\n",
    "time_durations = []\n",
    "transcriptions = []\n",
    "\n",
    "# Iterate over all files in the Categorical folder\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        with open(os.path.join(directory, filename), 'r', encoding='utf-8') as file:\n",
    "            for line in file:\n",
    "                parts = line.strip().split(' ', 2)  # Split into three parts: ID,time_duration, transcription\n",
    "                if len(parts) == 3:\n",
    "                    utterance_id, time_duration, transcription = parts\n",
    "                    utterance_ids.append(utterance_id)\n",
    "                    time_durations.append(time_duration)\n",
    "                    transcriptions.append(transcription)\n",
    "\n",
    "# Create a DataFrame to store the utterance IDs,Time and Transcriptions\n",
    "data = pd.DataFrame({\n",
    "    'utterance_id': utterance_ids,\n",
    "    'time_duration': time_durations,\n",
    "    'transcription': transcriptions\n",
    "})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "output_csv_path = os.path.join(directory, 'transcriptions.csv')  # Save the CSV in the same directory\n",
    "data.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(\"CSV file has been created successfully at\", output_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f1a3809-3fa1-419d-95e7-96516945c8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract Categorical Emotional Labels\n",
    "#emotional_labels.csv\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Directory containing the Categorical folder\n",
    "categorical_dir = 'E:/IIT-B/Dataset/Emotional_labels'\n",
    "\n",
    "# Initialize lists to store utterance IDs and emotion labels\n",
    "utterance_ids = []\n",
    "emotion_labels = []\n",
    "\n",
    "# Iterate over all files in the Categorical folder\n",
    "for filename in os.listdir(categorical_dir):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        with open(os.path.join(categorical_dir, filename), 'r', encoding='utf-8') as file:\n",
    "            for line in file:\n",
    "                parts = line.strip().split(' ', 1)  # Split into three parts: ID, transcription, emotion\n",
    "                if len(parts) == 2:\n",
    "                    utterance_id, emotion = parts\n",
    "                    utterance_ids.append(utterance_id)\n",
    "                    emotion_labels.append(emotion)\n",
    "\n",
    "# Create a DataFrame to store the utterance IDs and emotion labels\n",
    "data = pd.DataFrame({\n",
    "    'utterance_id': utterance_ids,\n",
    "    'emotion_label': emotion_labels\n",
    "})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "output_csv_path = os.path.join(dcategorical_dir, 'emotional_labels.csv')\n",
    "data.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(\"CSV file has been created successfully at\", output_csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f90b32e-f719-40d9-bf6c-8002f82a7a8e",
   "metadata": {},
   "source": [
    "Create transcriptions_with_emotions.csv file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6ecdbfc-6cc2-44c2-b549-aa33c8137dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the paths to the CSV files\n",
    "transcription_file_path = 'E:/IIT-B/Dataset/Transcriptions/transcriptions.csv'\n",
    "emotion_file_path = 'E:/IIT-B/Dataset/Emotional_labels/emotional_labels.csv'\n",
    "\n",
    "# Load the data\n",
    "try:\n",
    "    transcription_data = pd.read_csv(transcription_file_path)\n",
    "    emotion_data = pd.read_csv(emotion_file_path)\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "else:\n",
    "    # Merge the data\n",
    "    merged_data = transcription_data.merge(emotion_data, on='utterance_id', how='left')\n",
    "\n",
    "    # Save the merged data to a new CSV file\n",
    "    merged_data.to_csv('transcriptions_with_emotions.csv', index=False)\n",
    "\n",
    "    print(\"CSV file with emotional labels and additional data has been created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a408002c-653b-4020-86dc-3978b3fba94a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          utterance_id  actors            transcription  \\\n",
      "0  Ses01F_impro01_F000  Actor1               Excuse me.   \n",
      "1  Ses01F_impro01_F000  Actor1               Excuse me.   \n",
      "2  Ses01F_impro01_F000  Actor1               Excuse me.   \n",
      "3  Ses01F_impro01_M000  Actor2  Do you have your forms?   \n",
      "4  Ses01F_impro01_M000  Actor2  Do you have your forms?   \n",
      "\n",
      "                     emotion_label  \n",
      "0               :Neutral state; ()  \n",
      "1               :Neutral state; ()  \n",
      "2               :Neutral state; ()  \n",
      "3                 :Frustration; ()  \n",
      "4  :Neutral state; :Other; (bored)  \n"
     ]
    }
   ],
   "source": [
    "#add Actors column in transcriptions_with_emotions.csv\n",
    "import pandas as pd\n",
    "\n",
    "# Define the paths to the CSV file\n",
    "file_path = 'E:/IIT-B/Dataset/transcriptions_with_emotions.csv'\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Sample structure of the dataset\n",
    "# utterance_id           | transcription | emotion_label\n",
    "# ---------------------------------------\n",
    "\n",
    "# Ses01F_impro01_F000    | text          | happiness\n",
    "# Ses01F_impro01_F000    | text          | sadness\n",
    "\n",
    "#Extract Actor Information\n",
    "def extract_speaker(utterance_id):\n",
    "    # Assuming the speaker is identified by a character in the utterance ID\n",
    "    if '_F' in utterance_id and 'Ses01' in utterance_id :\n",
    "        return 'Actor1'\n",
    "    elif '_M' in utterance_id and 'Ses01' in utterance_id:\n",
    "        return 'Actor2'\n",
    "    elif '_F' in utterance_id and 'Ses02' in utterance_id :\n",
    "        return 'Actor3'\n",
    "        \n",
    "    elif '_M' in utterance_id and 'Ses02' in utterance_id :\n",
    "        return 'Actor4'\n",
    "    elif '_F' in utterance_id and 'Ses03' in utterance_id :\n",
    "        return 'Actor5'\n",
    "    elif '_M' in utterance_id and 'Ses03' in utterance_id :\n",
    "        return 'Actor6'\n",
    "    elif '_F' in utterance_id and 'Ses04' in utterance_id :\n",
    "        return 'Actor7'\n",
    "    elif '_M' in utterance_id and 'Ses04' in utterance_id :\n",
    "        return 'Actor8'\n",
    "    elif '_F' in utterance_id and 'Ses05' in utterance_id :\n",
    "        return 'Actor9'\n",
    "    elif '_M' in utterance_id and 'Ses05' in utterance_id :\n",
    "        return 'Actor10'\n",
    "    else:\n",
    "        return 'Unknown' \n",
    "\n",
    "# Apply the function to extract speaker information\n",
    "df['actors'] = df['utterance_id'].apply(extract_speaker)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df[['utterance_id', 'actors', 'transcription', 'emotion_label']].head())\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv('transcriptions_with_actors_and_emotions.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7587072f-0327-47dc-ba38-debff7f0f9e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "utterance_id     object\n",
      "time_duration    object\n",
      "transcription    object\n",
      "emotion_label    object\n",
      "actors           object\n",
      "dtype: object\n",
      "[':Neutral state; ()' ':Frustration; ()' ':Neutral state; :Other; (bored)'\n",
      " ':Other; (bored)' ':Surprise; ()' ':Anger; ()'\n",
      " ':Frustration; :Disgust; ()' ':Frustration; :Anger; ()'\n",
      " ':Frustration; :Disgust; :Anger; ()'\n",
      " ':Frustration; :Surprise; :Disgust; :Anger; ()' ':Disgust; ()'\n",
      " ':Disgust; :Anger; ()' ':Frustration; :Surprise; ()'\n",
      " ':Sadness; :Disgust; ()' ':Sadness; ()' ':Sadness; :Fear; ()'\n",
      " ':Frustration; :Sadness; ()' ':Sadness; :Other; (resigned)'\n",
      " ':Neutral state; :Other; (resigned)' ':Other; (confused)'\n",
      " ':Frustration; :Sadness; :Anger; ()' ':Other; (resigned)' ':Fear; ()'\n",
      " ':Anger; :Fear; ()' ':Happiness; ()' ':Excited; ()' ':Other; (amused)'\n",
      " ':Excited; :Surprise; ()' ':Excited; :Happiness; ()'\n",
      " ':Surprise; :Happiness; ()' nan ':Other; (annoyed)' ':Other; (pride)'\n",
      " ':Other; ()' ':Neutral state; :Other; (apologetic)'\n",
      " ':Frustration; :Surprise; :Anger; ()' ':Other; :Disgust; (sarcastic)'\n",
      " ':Neutral state; :Sadness; :Other; (apologetic)' ':Surprise; :Anger; ()'\n",
      " ':Other; :Fear; (apologetic)' ':Neutral state; :Sadness; ()'\n",
      " ':Other; (apologetic)' ':Other; :Anger; (sarcastic)'\n",
      " ':Surprise; :Fear; ()' ':Other; (worried)'\n",
      " ':Frustration; :Other; (worried)' ':Other; (indignation)'\n",
      " ':Other; :Disgust; (sarcastic tone)' ':Sadness; :Anger; ()'\n",
      " ':Excited; :Anger; ()' ':Frustration; :Fear; ()' ':Excited; :Fear; ()'\n",
      " ':Other; (anxious)' ':Other; (concern)' ':Other; (pensive)'\n",
      " ':Excited; :Sadness; ()' ':Other; :Happiness; (excited)'\n",
      " ':Other; :Surprise; (excited)' ':Other; (disappointed)'\n",
      " ':Neutral state; :Other; (uncertain)' ':Other; :Fear; (wonder)'\n",
      " ':Frustration; :Other; (disappointment)'\n",
      " ':Frustration; :Other; (sarcastic)' ':Other; :Happiness; (awe)'\n",
      " ':Other; (intrigued)' ':Other; (intruged)' ':Other; (intrigued, excited)'\n",
      " ':Sadness; :Other; (disappointment)'\n",
      " ':Frustration; :Sadness; :Surprise; ()' ':Other; (desperation)'\n",
      " ':Frustration; :Other; (confused)' ':Frustration; :Other; (resignation)'\n",
      " ':Frustration; :Other; (annoyance)' ':Sadness; :Other; (reminiscent)'\n",
      " ':Other; (reminiscent)' ':Other; :Happiness; (reminiscent)'\n",
      " ':Other; (realization)' ':Other; (content)'\n",
      " ':Sadness; :Other; (resignation)' ':Other; :Happiness; (sarcastic)'\n",
      " ':Other; (resignation)' ':Frustration; :Other; (desperation)'\n",
      " ':Sadness; :Other; (understanding)' ':Sadness; :Other; (unhappy)'\n",
      " ':Other; :Happiness; (content)' ':Neutral state; :Other; (content)'\n",
      " ':Other; (reassurance, relief)' ':Other; (relief)'\n",
      " ':Other; :Happiness; (relief)' ':Other; :Happiness; (carefree)'\n",
      " ':Other; (sarcasm)' ':Frustration; :Happiness; ()'\n",
      " ':Happiness; :Anger; ()' ':Other; :Anger; (annoyed)'\n",
      " ':Sadness; :Surprise; ()' ':Other; (melancolia)'\n",
      " ':Sadness; :Happiness; ()' ':Other; (nervous)'\n",
      " ':Excited; :Other; (nervous)' ':Other; (embrassment)'\n",
      " ':Frustration; :Other; (concern)' ':Other; (confuse)' ':Other; (despair)'\n",
      " ':Frustration; :Other; (annoyed)' ':Excited; :Frustration; ()'\n",
      " ':Fear; :Excited; ()' ':Frustration; :Excited; ()'\n",
      " ':Other; (reminiscing)' ':Other; (pleading...)'\n",
      " ':Frustration; :Other; (pleading)'\n",
      " ':Frustration; :Other; :Anger; (desperate)' ':Other; (sarcastic)'\n",
      " ':Neutral state; :Disgust; ()' ':Other; (exasperation)'\n",
      " ':Fear; :Anger; ()' ':Sadness; :Other; (concern)'\n",
      " ':Sadness; :Other; (confused)' ':Other; (confusion)'\n",
      " ':Other; (melancolic)' ':Other; (embarrased)' ':Other; (jealousy)'\n",
      " ':Anger; (This section should be under male emotion)'\n",
      " ':Other; (detached and amused)' ':Other; (supportive)'\n",
      " ':Excited; :Frustration; :Surprise; ()' ':Other; (relieved)'\n",
      " ':Frustration; :Other; (relief)' ':Excited; :Other; (relief)'\n",
      " ':Other; :Happiness; (nostaglic)' ':Neutral state; :Other; (nostaglic)'\n",
      " ':Other; (defensive)' ':Other; :Happiness; (nostalgic)'\n",
      " ':Other; (annnoyed)' ':Other; (Sarcastic tone)' ':Other; (reassuring)'\n",
      " ':Other; (determined, reassuring)' ':Sadness; :Other; (uncertainty)'\n",
      " ':Sadness; :Other; (remorseful)' ':Frustration; (confused)'\n",
      " ':Other; (indifferent)' ':Other; (shocked)' ':Other; (impressed)'\n",
      " ':Other; (proud)' ':Other; (offended)' ':Other; :Happiness; (amused)'\n",
      " ':Other; (inquisitive, and curious emotion)'\n",
      " ':Excited; :Neutral state; ()' ':Frustration; :Neutral state; ()'\n",
      " ':Sadness; :Other; (annoyed)' ':Frustration; (annoyed)'\n",
      " ':Other; :Surprise; (confused)' ':Other; (consoling)'\n",
      " ':Frustration; :Other; (sarcasm)' ':Other; (confused, concern)'\n",
      " ':Other; (cobncern)' ':Happiness; :Fear; ()'\n",
      " ':Neutral state; :Happiness; ()' ':Other; (exasperated)'\n",
      " ':Excited; (annoyed)' ':Other; (comcern)'\n",
      " ':Frustration; :Other; (confusion)'\n",
      " \":Other; (joking tone.  It's hard to guage actors seriousness about the situation.)\"\n",
      " ':Other; (optimistic)' ':Other; (reassurance)' ':Other; (sympathizing)'\n",
      " \":Neutral state; (I don't think this is part of the script.)\"\n",
      " \":Neutral state; (I don't this is part of the script.)\"\n",
      " ':Other; :Disgust; (annoyed)' ':Neutral state; :Other; (sarcastic)'\n",
      " ':Other; (annoyed,rude)' ':Frustration; :Other; (rude)'\n",
      " ':Fear; (anxious as in expecting something big to happen)'\n",
      " ':Other; (anxiety)' ':Other; (panic)' ':Other; (comforting)'\n",
      " ':Other; (male emotion, not female)' ':Frustration; :Anger; :Fear; ()'\n",
      " ':Neutral state; :Other; (hesitation)' ':Other; :Happiness; (relieved)'\n",
      " ':Disgust; :Fear; ()' ':Surprise; :Disgust; :Anger; ()'\n",
      " ':Sadness; :Anger; :Fear; ()' ':Frustration; :Sadness; :Disgust; ()'\n",
      " ':Other; (love)' ':Other; (mocking/ amused)'\n",
      " ':Sadness; :Other; (melancolia)' ':Neutral state; :Surprise; ()'\n",
      " ':Excited; :Other; (concern)']\n",
      "          utterance_id         time_duration            transcription  \\\n",
      "0  Ses01F_impro01_F000  [006.2901-008.2357]:               Excuse me.   \n",
      "1  Ses01F_impro01_F000  [006.2901-008.2357]:               Excuse me.   \n",
      "2  Ses01F_impro01_F000  [006.2901-008.2357]:               Excuse me.   \n",
      "3  Ses01F_impro01_M000  [007.5712-010.4750]:  Do you have your forms?   \n",
      "4  Ses01F_impro01_M000  [007.5712-010.4750]:  Do you have your forms?   \n",
      "\n",
      "                     emotion_label  actors  \n",
      "0               :Neutral state; ()  Actor1  \n",
      "1               :Neutral state; ()  Actor1  \n",
      "2               :Neutral state; ()  Actor1  \n",
      "3                 :Frustration; ()  Actor2  \n",
      "4  :Neutral state; :Other; (bored)  Actor2  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "emotion_label\n",
       "<class 'str'>      30117\n",
       "<class 'float'>      134\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.dtypes)\n",
    "print(df['emotion_label'].unique())\n",
    "print(df.head())\n",
    "df['emotion_label'].apply(type).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee9e83ef-bb84-4a10-8b7c-69c867b33920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     emotion_label         cleaned_emotion_label\n",
      "0               :Neutral state; ()  [\"['neutral']\", \"['state']\"]\n",
      "1               :Neutral state; ()  [\"['neutral']\", \"['state']\"]\n",
      "2               :Neutral state; ()  [\"['neutral']\", \"['state']\"]\n",
      "3                 :Frustration; ()           [\"['frustration']\"]\n",
      "4  :Neutral state; :Other; (bored)  [\"['neutral']\", \"['state']\"]\n",
      "object\n",
      "['[\"[\\'neutral\\']\", \"[\\'state\\']\"]' '[\"[\\'frustration\\']\"]' '[]'\n",
      " '[\"[\\'surprise\\']\"]' '[\"[\\'anger\\']\"]'\n",
      " '[\"[\\'frustration\\']\", \"[\\'disgust\\']\"]'\n",
      " '[\"[\\'frustration\\']\", \"[\\'anger\\']\"]'\n",
      " '[\"[\\'frustration\\']\", \"[\\'disgust\\']\", \"[\\'anger\\']\"]'\n",
      " '[\"[\\'frustration\\']\", \"[\\'surprise\\']\", \"[\\'disgust\\']\", \"[\\'anger\\']\"]'\n",
      " '[\"[\\'disgust\\']\"]' '[\"[\\'disgust\\']\", \"[\\'anger\\']\"]'\n",
      " '[\"[\\'frustration\\']\", \"[\\'surprise\\']\"]'\n",
      " '[\"[\\'sadness\\']\", \"[\\'disgust\\']\"]' '[\"[\\'sadness\\']\"]'\n",
      " '[\"[\\'sadness\\']\", \"[\\'fear\\']\"]'\n",
      " '[\"[\\'frustration\\']\", \"[\\'sadness\\']\"]'\n",
      " '[\"[\\'frustration\\']\", \"[\\'sadness\\']\", \"[\\'anger\\']\"]' '[\"[\\'fear\\']\"]'\n",
      " '[\"[\\'anger\\']\", \"[\\'fear\\']\"]' '[\"[\\'happiness\\']\"]' '[\"[\\'excited\\']\"]'\n",
      " '[\"[\\'excited\\']\", \"[\\'surprise\\']\"]'\n",
      " '[\"[\\'excited\\']\", \"[\\'happiness\\']\"]'\n",
      " '[\"[\\'surprise\\']\", \"[\\'happiness\\']\"]' ''\n",
      " '[\"[\\'frustration\\']\", \"[\\'surprise\\']\", \"[\\'anger\\']\"]'\n",
      " '[\"[\\'neutral\\']\", \"[\\'state\\']\", \"[\\'sadness\\']\"]'\n",
      " '[\"[\\'surprise\\']\", \"[\\'anger\\']\"]' '[\"[\\'surprise\\']\", \"[\\'fear\\']\"]'\n",
      " '[\"[\\'sadness\\']\", \"[\\'anger\\']\"]' '[\"[\\'excited\\']\", \"[\\'anger\\']\"]'\n",
      " '[\"[\\'frustration\\']\", \"[\\'fear\\']\"]' '[\"[\\'excited\\']\", \"[\\'fear\\']\"]'\n",
      " '[\"[\\'excited\\']\", \"[\\'sadness\\']\"]'\n",
      " '[\"[\\'frustration\\']\", \"[\\'sadness\\']\", \"[\\'surprise\\']\"]'\n",
      " '[\"[\\'frustration\\']\", \"[\\'happiness\\']\"]'\n",
      " '[\"[\\'happiness\\']\", \"[\\'anger\\']\"]'\n",
      " '[\"[\\'sadness\\']\", \"[\\'surprise\\']\"]'\n",
      " '[\"[\\'sadness\\']\", \"[\\'happiness\\']\"]'\n",
      " '[\"[\\'excited\\']\", \"[\\'frustration\\']\"]'\n",
      " '[\"[\\'fear\\']\", \"[\\'excited\\']\"]'\n",
      " '[\"[\\'frustration\\']\", \"[\\'excited\\']\"]'\n",
      " '[\"[\\'neutral\\']\", \"[\\'state\\']\", \"[\\'disgust\\']\"]'\n",
      " '[\"[\\'fear\\']\", \"[\\'anger\\']\"]'\n",
      " '[\"[\\'excited\\']\", \"[\\'frustration\\']\", \"[\\'surprise\\']\"]'\n",
      " '[\"[\\'excited\\']\", \"[\\'neutral\\']\", \"[\\'state\\']\"]'\n",
      " '[\"[\\'frustration\\']\", \"[\\'neutral\\']\", \"[\\'state\\']\"]'\n",
      " '[\"[\\'happiness\\']\", \"[\\'fear\\']\"]'\n",
      " '[\"[\\'neutral\\']\", \"[\\'state\\']\", \"[\\'happiness\\']\"]'\n",
      " '[\"[\\'frustration\\']\", \"[\\'anger\\']\", \"[\\'fear\\']\"]'\n",
      " '[\"[\\'disgust\\']\", \"[\\'fear\\']\"]'\n",
      " '[\"[\\'surprise\\']\", \"[\\'disgust\\']\", \"[\\'anger\\']\"]'\n",
      " '[\"[\\'sadness\\']\", \"[\\'anger\\']\", \"[\\'fear\\']\"]'\n",
      " '[\"[\\'frustration\\']\", \"[\\'sadness\\']\", \"[\\'disgust\\']\"]'\n",
      " '[\"[\\'neutral\\']\", \"[\\'state\\']\", \"[\\'surprise\\']\"]']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = 'E:/IIT-B/Dataset/transcriptions_with_actors_and_emotions.csv'  # Replace with your actual file path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "def clean_emotion_label(label):\n",
    "    if not isinstance(label, str):\n",
    "        return ''\n",
    "    # Remove brackets and the information within them\n",
    "    label = re.sub(r'\\(.*?\\)', '', label)\n",
    "    # Remove leading colons, trailing semicolons, and extra spaces\n",
    "    label = re.sub(r'[:;]', '', label).strip()\n",
    "    # Convert to lower case\n",
    "    label = label.lower()\n",
    "    label = re.sub(r'\\bother\\b', '', label, flags=re.IGNORECASE)\n",
    "    # Remove any extra whitespace\n",
    "    label = re.sub(r'\\s+', ' ', label).strip()\n",
    "    # Split the cleaned string into a list of words\n",
    "    words = label.split()\n",
    "    # Convert each word into a separate string representation\n",
    "    return [f\"['{word}']\" for word in words]\n",
    "    # Split the cleaned string into a list of words\n",
    "    #return label.split()\n",
    "\n",
    "# Apply the function to the emotion_label column\n",
    "df['cleaned_emotion_label'] = df['emotion_label'].apply(clean_emotion_label)\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "df['cleaned_emotion_label'] = df['cleaned_emotion_label'].astype(str)\n",
    "print(df[['emotion_label', 'cleaned_emotion_label']].head())\n",
    "print(df['cleaned_emotion_label'].dtype)\n",
    "print(df['cleaned_emotion_label'].unique())\n",
    "\n",
    "# Save the updated DataFrame back to a CSV file\n",
    "output_file_path = 'transcriptions_with_actors_and_emotions(cleaned).csv'  \n",
    "df.to_csv(output_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c6e9cc-2811-432b-add7-75fdb0eabd5f",
   "metadata": {},
   "source": [
    "Step 2: ANNOTATION PROCESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89d5cee3-f681-48d3-8ca0-896a4d1a0c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   actors            transcription         cleaned_emotion_label  \\\n",
      "0  Actor1               Excuse me.  [\"['neutral']\", \"['state']\"]   \n",
      "1  Actor1               Excuse me.  [\"['neutral']\", \"['state']\"]   \n",
      "2  Actor1               Excuse me.  [\"['neutral']\", \"['state']\"]   \n",
      "3  Actor2  Do you have your forms?           [\"['frustration']\"]   \n",
      "4  Actor2  Do you have your forms?  [\"['neutral']\", \"['state']\"]   \n",
      "\n",
      "       parsed_emotion_label  rating  \n",
      "0  [['neutral'], ['state']]     1.0  \n",
      "1  [['neutral'], ['state']]     1.0  \n",
      "2  [['neutral'], ['state']]     1.0  \n",
      "3         [['frustration']]     3.0  \n",
      "4  [['neutral'], ['state']]     1.0  \n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "# Load the CSV file\n",
    "file_path = 'transcriptions_with_actors_and_emotions(cleaned).csv' \n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "# Define the emotion-to-rating mapping\n",
    "emotion_ratings = {\n",
    "    'neutral': 1,\n",
    "    'state': 1,\n",
    "    'bored': 2,\n",
    "    'frustration': 3,\n",
    "    'happiness': 4,\n",
    "    'excited':5,\n",
    "    'surprise':4,\n",
    "    'fear':3, \n",
    "    'sadness':2, \n",
    "    'anger':4\n",
    "}\n",
    "\n",
    "# Define a function to parse the emotion label strings into lists\n",
    "def parse_emotion_label(label):\n",
    "    if not label:\n",
    "        return []\n",
    "    try:\n",
    "        return ast.literal_eval(label)\n",
    "    except (ValueError, SyntaxError):\n",
    "        return []\n",
    "\n",
    "# Define a function to calculate the rating based on the parsed emotion labels\n",
    "def calculate_rating(emotion_list):\n",
    "    if not emotion_list:\n",
    "        return 0  \n",
    "    # Flatten the list and remove brackets and quotes\n",
    "    flat_list = [emotion.strip(\"[]'\") for sublist in emotion_list for emotion in sublist.split(',')]\n",
    "    # Map each emotion to its rating and calculate the sum\n",
    "    rating_sum = sum(emotion_ratings.get(emotion.strip(), 0) for emotion in flat_list)\n",
    "    # Calculate the average rating\n",
    "    return rating_sum / len(flat_list)\n",
    "\n",
    "# Parse the emotion_label strings into lists\n",
    "df['parsed_emotion_label'] = df['cleaned_emotion_label'].apply(parse_emotion_label)\n",
    "\n",
    "# Calculate the rating based on the parsed emotion labels\n",
    "df['rating'] = df['parsed_emotion_label'].apply(calculate_rating)\n",
    "\n",
    "# Display the DataFrame with the new rating column\n",
    "print(df[['actors', 'transcription', 'cleaned_emotion_label', 'parsed_emotion_label', 'rating']].head())\n",
    "\n",
    "# Save the updated DataFrame back to a CSV file\n",
    "#output_file_path = 'updated_file_with_ratings.csv'  \n",
    "#df.to_csv(output_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5cc2d974-f758-4646-a907-c4943fcea551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  item_id  rating\n",
      "0        0        3     1.0\n",
      "1        0        3     1.0\n",
      "2        0        3     1.0\n",
      "3        2       19     3.0\n",
      "4        2       19     1.0\n",
      "   user_id  item_id  rating\n",
      "0        0        3     1.0\n",
      "1        0        3     1.0\n",
      "2        0        3     1.0\n",
      "3        2       19     3.0\n",
      "4        2       19     1.0\n"
     ]
    }
   ],
   "source": [
    "#Encode User and Item IDs to Integer Indices:\n",
    "# Load the cleaned CSV file\n",
    "df = pd.read_csv('updated_file_with_ratings.csv')\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode user (actor) and item (utterance_id) IDs\n",
    "user_encoder = LabelEncoder()\n",
    "item_encoder = LabelEncoder()\n",
    "\n",
    "df['user_id'] = user_encoder.fit_transform(df['actors'])\n",
    "df['item_id'] = item_encoder.fit_transform(df['utterance_id'])\n",
    "\n",
    "# Display the DataFrame with encoded IDs\n",
    "print(df[['user_id', 'item_id', 'rating']].head())\n",
    "\n",
    "\n",
    "# Create the user-item interaction DataFrame\n",
    "interaction_df = df[['user_id', 'item_id', 'rating']]\n",
    "\n",
    "# Display the interaction DataFrame\n",
    "print(interaction_df.head())\n",
    "\n",
    "# Save the interaction DataFrame to CSV\n",
    "#interaction_df.to_csv('user_item_interactions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3145152-621e-4d63-8456-7d3b9b17dc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Flatten, Dense, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f6d1e439-e196-4a16-9aab-e72cd8d49720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the user-item interaction data\n",
    "interaction_df = pd.read_csv('user_item_interactions.csv')\n",
    "\n",
    "# Extract unique user and item IDs\n",
    "user_ids = df['user_id'].unique()\n",
    "item_ids = df['item_id'].unique()\n",
    "\n",
    "# Normalize the ratings if necessary\n",
    "scaler = MinMaxScaler()\n",
    "interaction_df['rating'] = scaler.fit_transform(interaction_df[['rating']])\n",
    "\n",
    "# Define mappings\n",
    "user2user_encoded = {user_id: i for i, user_id in enumerate(user_ids)}\n",
    "item2item_encoded = {item_id: i for i, item_id in enumerate(item_ids)}\n",
    "item_encoded2item = {i: item_id for item_id, i in item2item_encoded.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "02a85340-6fdb-4b03-957c-293a4d86c691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "train, test = train_test_split(interaction_df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d1e87843-afc0-4753-bf65-5d794b77b4b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0804 - mae: 0.2381 - val_loss: 0.0707 - val_mae: 0.2151\n",
      "Epoch 2/20\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0506 - mae: 0.1738 - val_loss: 0.0704 - val_mae: 0.2055\n",
      "Epoch 3/20\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0402 - mae: 0.1500 - val_loss: 0.0727 - val_mae: 0.2037\n",
      "Epoch 4/20\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0366 - mae: 0.1411 - val_loss: 0.0786 - val_mae: 0.2057\n",
      "Epoch 5/20\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0358 - mae: 0.1380 - val_loss: 0.0800 - val_mae: 0.2060\n",
      "Epoch 6/20\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0347 - mae: 0.1357 - val_loss: 0.0800 - val_mae: 0.2065\n",
      "Epoch 7/20\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0351 - mae: 0.1357 - val_loss: 0.0841 - val_mae: 0.2085\n",
      "Epoch 8/20\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0346 - mae: 0.1346 - val_loss: 0.0832 - val_mae: 0.2084\n",
      "Epoch 9/20\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0340 - mae: 0.1326 - val_loss: 0.0853 - val_mae: 0.2099\n",
      "Epoch 10/20\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0338 - mae: 0.1319 - val_loss: 0.0840 - val_mae: 0.2092\n",
      "Epoch 11/20\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0333 - mae: 0.1306 - val_loss: 0.0855 - val_mae: 0.2099\n",
      "Epoch 12/20\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0330 - mae: 0.1301 - val_loss: 0.0822 - val_mae: 0.2079\n",
      "Epoch 13/20\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0338 - mae: 0.1314 - val_loss: 0.0885 - val_mae: 0.2131\n",
      "Epoch 14/20\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0336 - mae: 0.1316 - val_loss: 0.0855 - val_mae: 0.2096\n",
      "Epoch 15/20\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0334 - mae: 0.1309 - val_loss: 0.0881 - val_mae: 0.2120\n",
      "Epoch 16/20\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0339 - mae: 0.1311 - val_loss: 0.0872 - val_mae: 0.2113\n",
      "Epoch 17/20\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0332 - mae: 0.1291 - val_loss: 0.0849 - val_mae: 0.2091\n",
      "Epoch 18/20\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0335 - mae: 0.1302 - val_loss: 0.0874 - val_mae: 0.2108\n",
      "Epoch 19/20\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0332 - mae: 0.1295 - val_loss: 0.0875 - val_mae: 0.2121\n",
      "Epoch 20/20\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0325 - mae: 0.1279 - val_loss: 0.0835 - val_mae: 0.2086\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "MAE: 2.310239280276214, MSE: 6.438667072680987, RMSE: 2.537452871026571\n",
      "Accuracy: 0.6331184928111055, Precision: 0.6339956587076306, Recall: 0.9926797385620915, F1-score: 0.7737925412675769\n"
     ]
    }
   ],
   "source": [
    "# Define the number of unique users and items\n",
    "num_users = interaction_df['user_id'].nunique()\n",
    "num_items = interaction_df['item_id'].nunique()\n",
    "\n",
    "# Define the embedding dimension\n",
    "embedding_dim = 50\n",
    "\n",
    "# User input and embedding\n",
    "user_input = Input(shape=(1,), name='user_input')\n",
    "user_embedding = Embedding(input_dim=num_users, output_dim=embedding_dim, name='user_embedding')(user_input)\n",
    "user_vec = Flatten(name='user_flatten')(user_embedding)\n",
    "\n",
    "# Item input and embedding\n",
    "item_input = Input(shape=(1,), name='item_input')\n",
    "item_embedding = Embedding(input_dim=num_items, output_dim=embedding_dim, name='item_embedding')(item_input)\n",
    "item_vec = Flatten(name='item_flatten')(item_embedding)\n",
    "\n",
    "# Concatenate user and item vectors\n",
    "concat = Concatenate()([user_vec, item_vec])\n",
    "\n",
    "# Add dense layers\n",
    "dense = Dense(128, activation='relu')(concat)\n",
    "dense = Dense(64, activation='relu')(dense)\n",
    "output = Dense(1, activation='sigmoid')(dense)\n",
    "\n",
    "# Build the model\n",
    "model = Model(inputs=[user_input, item_input], outputs=output)\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit([train['user_id'], train['item_id']], train['rating'], \n",
    "                    validation_data=([test['user_id'], test['item_id']], test['rating']),\n",
    "                    epochs=20, batch_size=64)\n",
    "\n",
    "# Evaluate the model\n",
    "predictions = model.predict([test['user_id'], test['item_id']])\n",
    "predictions = scaler.inverse_transform(predictions)\n",
    "\n",
    "# Calculate metrics\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "mae = mean_absolute_error(test['rating'], predictions)\n",
    "mse = mean_squared_error(test['rating'], predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f'MAE: {mae}, MSE: {mse}, RMSE: {rmse}')\n",
    "\n",
    "# Convert predictions and test ratings back to original scale\n",
    "test['rating'] = scaler.inverse_transform(test[['rating']])\n",
    "predictions = scaler.inverse_transform(predictions)\n",
    "\n",
    "# Binarize ratings for classification metrics\n",
    "test['binary_rating'] = np.where(test['rating'] >= 3, 1, 0)\n",
    "binary_predictions = np.where(predictions >= 3, 1, 0)\n",
    "\n",
    "# Calculate accuracy, precision, recall, and F1-score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "accuracy = accuracy_score(test['binary_rating'], binary_predictions)\n",
    "precision = precision_score(test['binary_rating'], binary_predictions)\n",
    "recall = recall_score(test['binary_rating'], binary_predictions)\n",
    "f1 = f1_score(test['binary_rating'], binary_predictions)\n",
    "\n",
    "print(f'Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, F1-score: {f1}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "488b2a00-01c8-4756-8a41-d7500e0037f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0331 - mae: 0.1288 - val_loss: 7.0929 - val_mae: 2.3288\n",
      "Epoch 2/20\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0327 - mae: 0.1272 - val_loss: 7.1350 - val_mae: 2.3368\n",
      "Epoch 3/20\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0332 - mae: 0.1285 - val_loss: 7.0917 - val_mae: 2.3288\n",
      "Epoch 4/20\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0331 - mae: 0.1283 - val_loss: 7.0975 - val_mae: 2.3295\n",
      "Epoch 5/20\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0323 - mae: 0.1270 - val_loss: 7.1049 - val_mae: 2.3310\n",
      "Epoch 6/20\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0328 - mae: 0.1272 - val_loss: 7.1270 - val_mae: 2.3357\n",
      "Epoch 7/20\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0330 - mae: 0.1278 - val_loss: 7.1259 - val_mae: 2.3350\n",
      "Epoch 8/20\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0324 - mae: 0.1260 - val_loss: 7.1132 - val_mae: 2.3334\n",
      "Epoch 9/20\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0328 - mae: 0.1271 - val_loss: 7.1143 - val_mae: 2.3332\n",
      "Epoch 10/20\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0316 - mae: 0.1246 - val_loss: 7.1285 - val_mae: 2.3354\n",
      "Epoch 11/20\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0333 - mae: 0.1284 - val_loss: 7.1055 - val_mae: 2.3319\n",
      "Epoch 12/20\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0329 - mae: 0.1273 - val_loss: 7.1456 - val_mae: 2.3395\n",
      "Epoch 13/20\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0330 - mae: 0.1266 - val_loss: 7.1669 - val_mae: 2.3428\n",
      "Epoch 14/20\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0325 - mae: 0.1266 - val_loss: 7.1263 - val_mae: 2.3364\n",
      "Epoch 15/20\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0324 - mae: 0.1267 - val_loss: 7.0878 - val_mae: 2.3275\n",
      "Epoch 16/20\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0325 - mae: 0.1266 - val_loss: 7.1007 - val_mae: 2.3290\n",
      "Epoch 17/20\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0332 - mae: 0.1276 - val_loss: 7.0878 - val_mae: 2.3275\n",
      "Epoch 18/20\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0325 - mae: 0.1255 - val_loss: 7.0978 - val_mae: 2.3296\n",
      "Epoch 19/20\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0328 - mae: 0.1266 - val_loss: 7.1120 - val_mae: 2.3339\n",
      "Epoch 20/20\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0332 - mae: 0.1274 - val_loss: 7.1390 - val_mae: 2.3388\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit([train['user_id'], train['item_id']], train['rating'], \n",
    "                    validation_data=([test['user_id'], test['item_id']], test['rating']),\n",
    "                    epochs=20, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "88885cf4-1de9-4277-993d-38c14c3a2b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "MAE: 1.0545203867611068, MSE: 2.2101141229742782, RMSE: 1.4866452579463192\n",
      "Accuracy: 0.9631465873409354, Precision: 0.9740237975532093, Recall: 0.9884353741496599, F1-score: 0.9811766691989533\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "predictions = model.predict([test['user_id'], test['item_id']])\n",
    "predictions = scaler.inverse_transform(predictions)\n",
    "\n",
    "# Calculate metrics\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "mae = mean_absolute_error(test['rating'], predictions)\n",
    "mse = mean_squared_error(test['rating'], predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f'MAE: {mae}, MSE: {mse}, RMSE: {rmse}')\n",
    "\n",
    "# Convert predictions and test ratings back to original scale\n",
    "test['rating'] = scaler.inverse_transform(test[['rating']])\n",
    "predictions = scaler.inverse_transform(predictions)\n",
    "\n",
    "# Binarize ratings for classification metrics\n",
    "test['binary_rating'] = np.where(test['rating'] >= 3, 1, 0)\n",
    "binary_predictions = np.where(predictions >= 3, 1, 0)\n",
    "\n",
    "# Calculate accuracy, precision, recall, and F1-score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "accuracy = accuracy_score(test['binary_rating'], binary_predictions)\n",
    "precision = precision_score(test['binary_rating'], binary_predictions)\n",
    "recall = recall_score(test['binary_rating'], binary_predictions)\n",
    "f1 = f1_score(test['binary_rating'], binary_predictions)\n",
    "\n",
    "print(f'Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, F1-score: {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "595c2bf0-8d4d-4d18-9327-27a9cc40ef8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Recommendations for User 1:\n",
      "Item ID: 9458, Predicted Rating: 0.9909\n",
      "Item ID: 1518, Predicted Rating: 0.9907\n",
      "Item ID: 2098, Predicted Rating: 0.9906\n",
      "Item ID: 6636, Predicted Rating: 0.9906\n",
      "Item ID: 6593, Predicted Rating: 0.9905\n",
      "Item ID: 7311, Predicted Rating: 0.9903\n",
      "Item ID: 7723, Predicted Rating: 0.9901\n",
      "Item ID: 8796, Predicted Rating: 0.9901\n",
      "Item ID: 1021, Predicted Rating: 0.9900\n",
      "Item ID: 7636, Predicted Rating: 0.9900\n"
     ]
    }
   ],
   "source": [
    "def get_top_n_recommendations(user_id, model, user2user_encoded, item_encoded2item, n=10):\n",
    "    # Step 1: Get the encoded ID for the user\n",
    "    encoded_user_id = user2user_encoded.get(user_id)\n",
    "    \n",
    "    if encoded_user_id is None:\n",
    "        raise ValueError(f\"User {user_id} not found in the dataset.\")\n",
    "    \n",
    "    # Step 2: Create an array of all possible item IDs\n",
    "    all_item_ids = np.array(list(item_encoded2item.keys()))\n",
    "    \n",
    "    # Step 3: Create an array of repeated user IDs for prediction\n",
    "    user_array = np.array([encoded_user_id] * len(all_item_ids))\n",
    "    \n",
    "    # Step 4: Predict the ratings for all items for the given user\n",
    "    predictions = model.predict([user_array, all_item_ids], verbose=0).flatten()\n",
    "    \n",
    "    # Step 5: Get the top N item IDs based on the highest predicted ratings\n",
    "    top_n_indices = np.argsort(predictions)[-n:][::-1]  # Sort predictions and get top N\n",
    "    \n",
    "    # Step 6: Decode the top item IDs to their original values\n",
    "    top_n_item_ids = [item_encoded2item[idx] for idx in top_n_indices]\n",
    "    \n",
    "    # Return the top N item IDs and their corresponding predicted ratings\n",
    "    return top_n_item_ids, predictions[top_n_indices]\n",
    "\n",
    "# Example Usage\n",
    "user_id = 1  # Replace with the ID of the user you want recommendations for\n",
    "\n",
    "# Get the top 10 item recommendations for the specified user\n",
    "top_items, top_ratings = get_top_n_recommendations(user_id, model, user2user_encoded, item_encoded2item, n=10)\n",
    "\n",
    "print(f\"Top 10 Recommendations for User {user_id}:\")\n",
    "for item_id, rating in zip(top_items, top_ratings):\n",
    "    print(f\"Item ID: {item_id}, Predicted Rating: {rating:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6302497-518e-42b5-87fb-8526d0135c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512639e5-1c0b-45a3-ad3b-a2f0d4d925b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4e3a5d-51bc-464c-ba4f-5ba12921a648",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350310e0-d00f-4183-b7aa-22b6909726bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8398424f-405e-4bc4-be5f-c7f8d2e85497",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e11dc02-ea86-44a8-9383-d3a720e18c8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8006dc0f-2b47-43cc-b643-5b7a3516b499",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e483b333-1ad7-43f7-9164-75de390d9bc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8571ef14-506f-4917-83ae-b98c713453ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71235c3b-2d26-47b1-997d-cfd012be5439",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e53c99-e9bf-49e0-80c2-6e1a8c52cb81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc00143f-93d4-455c-a673-b31155e5c485",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75809f7f-65c9-40a9-a706-bc1d23003d95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b56298a-9931-42dc-acd2-2dc8998764da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026c0c0b-b4c7-4f2c-a0a8-72b6e787ac65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7975065e-6482-4587-9bf9-b839b04fd3bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13eb2eca-70d5-47c5-9277-79dd864b9bf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fbf2dc-c2c7-4fa4-8deb-2166e834bbd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
